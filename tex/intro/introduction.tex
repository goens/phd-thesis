Programming computers is notoriously difficult.
Indeed, people learning to program usually struggle, paradoxically, with the fact that the computer does precisely what they tell it to do. 
This is confusing not because a computer program is executed faithfully, but rather, because humans think at a very different level of abstraction.

It is certainly true that instructions in computer architectures are at a completely different level of abstraction than the instructions we give each other.
However, most programs are also not written at the level of the architecture.
Programming languages are designed with increasingly improving abstractions, to make it easier for programmers to express themselves.
Complementary to these efforts are compilers, which serve as bridge between the levels of abstraction.
Ideally, a compiler translates the abstract human-level expressions into efficient machine-level instructions.
While we have made significant progress, this task has proven to be dauntingly difficult.

Traditionally, we have put the resarch and effort into optimizing the execution of a single core.
Most of the progress of decades of research in programming language and compilers revolves around this single-core model.
In the last decade or two, however, with the multicore era, this challenge has increased dramatically.
Now we have to use and coordinate multiple cores, commonly with different capabilities.
The widespread programming language abstractions and compiler analyses of today are not well-suited to tackle this challenge.

\section{The Multicore Era}

On the hardware side, the last two decades have firmly established what we call the multicore era.
Modern computing systems are almost universally composed of multiple logical cores, and there is a clear trend of increasing both the number and the heterogeneity of these cores.
This increasing complexity brings about an increasing challenge in taming it.

\begin{figure}[h]
	\centering
   \resizebox{0.9\textwidth}{!}{\input{generated/moore.tex}}
   \caption{Chip trends as obtained from~\cite{microprocessordata}. The lines present the exponential growth prediction if considering data up until the year 2000.}
	\label{fig:multicore_era}
\end{figure}


%Multicore Era
Both the execution frequency and the closely intertwined single-core processing speed of computing systems increased exponentially up until the early 2000s (cf. Figure~\ref{fig:multicore_era}), an empirical fact observed by Gordon Moore in 1965~\cite{moore}.
Since the early 2000s, however, while tranistor size continue to decrease, the exponential frequency scaling has stopped (cf. Figure~\ref{fig:multicore_era}).
Individual and clever designs have continued to improve single-processor speed, albeit at a significantly slower rate.
Instead, most improvements in microchips in raw processing power have come from a paradigm switch.
Hardware designers resorted to develop multicores, microchips composed of multiple logical cores that can execute in parallel.
Additionally, since different use-cases benefit from different computing core architectures, the inclusion of multiple chips has paved the way for heterogeneity.
This has resulted in a multicore era of computing.

A programmer writing a piece of C code in the early 1970s would automatically benefit from the increasing processing speeds.
By recompiling her code for a processor $10 \times$ faster, she could very roughly expect her code also to run about $10 \times$ as fast.% Do I want to make this concrete (with Processor names?)
Nowadays thus, a programmer writing a piece of (sequential) C code in the early 2000s cannot expect anywhere near a $100$-fold increase in performance today when she uses a microchip with $100 \times$ the number of transistors.
At least not without fundamentally restructuring her code to exploit parallelism.
Contemportary systems aimed at performance almost ubiqutiously consist of multicore chips, in many cases heterogeneous, which tremendously increases the system complexity.
The trend is clear, the number of cores, heterogeneity and overall system complexity will only continue to increase.

%something about network-on-chip, emerging memories, and hierarchical topologies
As the number of cores in a chip keeps increasing, the importance of coordination and communication between the cores raises as well.
Memory latency and bandwidth has been a bottleneck for many clasess of applications for a while.
In the case of manycores, which are multicores where the number of cores goes over several dozens, even to hunderds or thousands, the on-chip memory subsystem becomes a central design point of the chip.
Systems based on \ac{NoC} technology become necessary, lest a single bus interconnect becomes the bottleneck of the system when thousands of cores want to communicate simmultaneously through it.

\begin{figure}[h]
	\centering
   \resizebox{0.5\textwidth}{!}{\input{figures/haec.tex}}
   \caption{The HAEC architecture~\cite{HAEC} has multiple levels of hierarchy: on-chip, intra-board (optical links) and inter-board (wireless).} 
	\label{fig:haec}
\end{figure}

In fact, for a multitude of reasons, manycores are commonly designed in a hierarchical fashion.
Smaller clusters of cores locally interconnected communicate between each other and off-chip via a larger \ac{NoC}.
These clusters and systems are usually heterogeneous as well, like the Karlay MPPA3 Coolidge, with includes accelerators for cryptography and secure cores, alongside general purpose cores.
Some systems even propose multiple layers of hierarchy, like the three layers of the HAEC topology~\cite{HAEC}, depicted in Figure~\ref{fig:haec}.
This is a proposed 3D stacked system with multiple boards each with multiple chips, not a single chip with this complex interconnect.
However, this design could allow for very low latencies, such that challenges of programming it are comparable to those of programming such a topology in an on-chip memory subsystem.
What happens if the mulicores in this system are similar to the Karlay MPPA3 Coolidge? This would yield more than $5000$ heterogeneous cores connected at five levels of hierarchy in different topologies.
More generally, complex topologies with possibly multi-level hierachies, add an additional layer of complexity to modern manycore systems besides heterogeneity and concurrency.

\section{Programming Multicores}

As already mentioned, programming is notoriously difficult since it translates from the level of abstraction of human interactions to the instructions of a computing system.
The multicore era greatly aggravates this already difficult problem.
We speak of a software productivity gap~\cite{castrillon2014thesis,ecker2009hardware}\index{software productivity gap}. 
The productivity of developers cannot keep up with the pace of developments in hardware.

When programming multicore systems, abstractions that proved very useful for programming single-cores become inadaquate.
An universal concept in programming is that of repeating an action multiple times, or looping. 
This perfectly exemplifies the differences in abstractions and how they become inadequate for multicore systems.

For example, consider the task of iterating through a bunch of pictures and determining which of them contain cats.
For instructing a human, we can probably say something like ``look through those pictures and sort out the ones have cats''.
A modern x86 chip, on the other hand, would understand something closer to this:

\begin{minted}{Nasm}
LBB0_1:                                 
	cmp	dword ptr [rbp - 56], 10
	jge	LBB0_4
	mov	edi, dword ptr [rbp - 56]
	call	_read_file
	mov	qword ptr [rbp - 64], rax
	mov	rdi, qword ptr [rbp - 64]
	call	_contains_cats
	movsxd	rcx, dword ptr [rbp - 56]
	mov	dword ptr [rbp + 4*rcx - 48], eax
	mov	eax, dword ptr [rbp - 56]
	add	eax, 1
	mov	dword ptr [rbp - 56], eax
	jmp	LBB0_1
LBB0_4:
	mov	eax, dword ptr [rbp - 52]
	mov	rcx, qword ptr [rip + ___stack_chk_guard@GOTPCREL]
	mov	rcx, qword ptr [rcx]
	mov	rdx, qword ptr [rbp - 8]
	cmp	rcx, rdx
	mov	dword ptr [rbp - 68], eax 
	jne	LBB0_6
\end{minted}

This snippet is a very oversimplified version of the task, but it serves to make the point.
Where we abstractly tell a human to look through the pictures and they undestand them as a whole set, interpreting themselves how to go through the set.
On the other hand, we instruct the machine to iterate through them by a series of very fine grained commands.
We need to set certain registers to contain the right memory addresses, before calling an instruction to operate on them.
Here we then call external functions that do the reading and cat identification.
To then loop through the pictures here, simplified, we repeat this reading and indetifying by jumping to a previous point in the sequence of instructions.
Even this x86 assembly snippet is already an abstraction, not only because it uses human-readable mnemonics for the instructions, but more so because it also abstracts away the concrete memory addresses.
In practice, however, almost no one would write this assembly code. Instead, they could write something closer to this (equivalent) C snippet:
\begin{minted}{C}
for(i = 0; i < N; i++){
    char *f;
    f = read_file(i);
    results[i] = contains_cats(f); 
}
\end{minted}

Notice how the register management and several other low-level details are abstracted away.
The end of the loop is very clear to read, as we know when we have reached the final picture.
We can certainly say this is at a level of abstraction between the human and machine instructions contrasted above.
However, the very widespread \texttt{for} instruction we used here also has the inherently sequential semantics exhibited by the machine code above.
The semantics of the for loop are that the loop body will execute completely.
After each iteration of the body, the increment expression is executed (usually incrementing the iteration variable), and the condition is evaluated, deciding wether to continue iterating.
Indeed, in the two (equivalent) snippets above, we don't know how the functions\texttt{read\_file} and \texttt{contains\_cats} work.
Do they have an inner state, or side effects?
We don't know if we can call \texttt{read\_file} in a different order, or multiple times in parallel.
Perhaps it is internally keeping a single reference to the iterator of the image files and doing so would break the logic.
The \texttt{for} instruction is very useful to abstract away the logic of registers and instruction jumps, but not a useful abstraction for expressing concurrency.
A similar construct exists in functional programming, \texttt{map}\index{\texttt{map} function}, which generally does not have this implicit sequential semantics.
The \texttt{map} instruction is what is called a higher-order function\index{higher-order function}, taking a function as an argument and applying it to a list or any iterable object, in general.
The same cat-identifying snippet, in Haskell, can be written as follows:
\begin{minted}{Haskell}
result = map (contains_cats . read_file) pictures
\end{minted}

While the language separates statfull and stateless computation, allowing a great analysis of concurrency, there are reasons why Haskell is not the most widespread language for embedded systems.
For example, garbage collection makes execution times very unpredictable.
Similarly, the lazyness of the language adds a performance penalty to large complex computations.
Compiling Haskell code to an efficient single-core execution is significantly more challenging than with the C code.
The lazyness also makes it difficult to reason about time in the computation.
This is crucial in some application domains, like \ac{CPS}, where the systems interact with their environment.
The \texttt{map} abstraction as implemented in Haskell is thus not well-suited to the domain of \ac{CPS}.
In general, we are faced with trade-offs between abstract expressability and translatability to an efficient execution.
At its core, the challenge is about choosing the right models and corresponding abstractions for a particular domain.

\section{Software Synthesis}

Models play different roles in science and engineering.
E.A. Lee explains this well in~\cite{lee2017plato}.
He argues that scientist adapt their models to fit experiments in the world, while engineers adapt designs in the world to fit their models.
Indeed, for some fundamental principles of computation, like $\lambda$-calculus, are discovered instead of invented~\cite{wadler2015propositions}.
Those might fit in the first paradigm, giving computer science a justification for its name.
In the case of programming multicore systems, however, the problem is clearly in the second realm: we need to engineer good models~\cite{lee2006problem}.
No serious argument can be made for languages like C or Haskell, nor the x86 instruction-set; They were invented, not discovered.

There are different ways of finding and exploiting the right models for programming multicores.
It is unlikely that there is a single right model for this.
Different models are differently suitable for different use-cases. 
For example, applicative functors in functional programming~\cite{marlow2014haxl} seem to be a great model for expressing \acs{I/O} concurrency in microservice-based systems.
%We will discuss this example in Chapter~\ref{chap}.
As mentioned before, however, Haskell and its underlying model are not a great fit for \ac{CPS}.

For \ac{CPS} and, embedded systems in general, there is a family of methods called software synthesis~\cite{ritz1992softwaresynthesis,abbott1993softwaresynthesis,lin1998softwaresynthesis,bhartacharyya2000softwaresynthesis,pino1995softwaresynthesis,bhattacharyya2012softwaresynthesis}\index{software synthesis}.
It is a family of methods devised precisely to help with the burden of fully exploiting the capabilities of modern multicores.
Inspired by hardware design flows, it aims to bridge the ensuing (software) productivity gap by integrating knowledge of the application and target multicore architecture into the compilation process.
At the core of these methods lies a shift in the programming model.
Instead of the de-facto sequential, shared-memory model, programmers express the code in diverse \acp{MoC}.
This makes the underlying model explicit, not implicit as is the case in most programming languages.

These models expose the structure of the computation in ways that permit a compiler to reason about its parallel execution, even in the prescence of heterogeneous hardware.
Aided by abstract models of the target archicecture, we can design compilers for multicore systems that devise execution strategies specialized to the target architecture and applications.
Depending on the flow, the target archicecture can be implicit in the methodology~\cite{ritz1992softwaresynthesis} or be an explicit input to the flow~\cite{maps}
This can be realized for example by finding efficient mappings, i.e. allocations of computational and communication resources to the different parts of an application.

As mentioned above, the central principle behind software synthesis is the underlying model of computation. 
Some approaches~\cite{lin1998softwaresynthesis} use very general models, like Petri Nets~\cite{petri1962nets}, while others~\cite{ritz1992softwaresynthesis} very constrained models like \acp{SDF}~\cite{lee1987sdf}.
Most allow for multiple models~\cite{bhartacharyya2000softwaresynthesis,pino1995softwaresynthesis,bhattacharyya2012softwaresynthesis}, generally dataflow models.
Making the model explicit just makes it easier to see the trade-off between expressability and translatability to an efficient execution.
The advantage of models like Petri-Nets is that they are very general and can express virtually any computation.
On the other hand, very constrained models, like \ac{SDF} provide behavioral guarantees that permit several optimization, like static schedules and channel bounds~\cite{Parks:M95/105}.

Several more modern flows~\cite{thiele2007DOL,maps,pimentel2006systematic,kangas2006uml} have settled at the \ac{KPN} model.
Originally meant as denotational semantics for parallelism~\cite{kahn74}, the model has been shown to be compatible with the dataflow~\cite{lee1995dataflow}.
Kahn Process Networks are provably deterministic~\cite{kahn74}, which is not the case for other models, e.g. Petri Nets.
In a canonical sense, \acp{KPN} are more general than most dataflow models, and represent the most general deterministic dataflow model of computation~\cite{lee_matsikoudis_semantics}.
In this thesis we will focus on a software synthesis flow~\cite{maps,castrillon2014thesis} based on \ac{KPN}.
Figure~\ref{fig:software_synthesis_flows} shows the general structure of the flow and the four main abstractions as we identify them for our analysis~\cite{goens_mcsoc16}.
Chapter~\ref{chap} will review these abstractions, including the models of computation above, and their relationships.

\begin{figure}[h]
	\centering
   \resizebox{0.75\textwidth}{!}{\input{figures/software_synthesis_flow.tex}}
   \caption{The four main abstractions in Software Synthesis in the Example of a \acs{KPN}-based flow.} 
	\label{fig:software_synthesis_flows}
\end{figure}

\section{Contribution}

In this thesis we seek to improve the tools we use for understanding and tackling the problems we've introduced. 
We work around in a model-based perspective and consider the trade-off we've introduced, between abstract expressability and translatability to an efficient execution
To consider this we tackle the problem from both sides: the models and the compilers, in a very general sense, that translate to an efficient execution.
The main idea behind this thesis is that the underlying models endow the problem with structure.
We can then identify this structure (mathematically) and leverage it to improve our solutions.
Again there are two ways of doing this: 
\begin{enumerate}
\item by taking a concrete flow and improving it leveraging its own structure, or
\item by changing the underlying model in a way that improves the balance in some way in the trade-off above.
\end{enumerate}
These make the two parts of this thesis.


The first part focuses on software synthesis in the domain of \acp{CPS} and generally embedded systems.
While some of the difficulties are general of all computing systems, the largest challenges are usually specific to an application domain.
This thesis focuses on one such domain, of \acp{CPS} and other high-performance embedded systems running on \acp{MPSoC}.
In particular, we focus on a concrete software synthesis flow~\cite{maps,castrillon2014thesis} based on \acp{KPN} (cf. Fig.~\ref{fig:software_synthesis_flows}). Chapter~\ref{chap:background} introduces this flow and the corresponding background.


% Exploiting Structure in Dataflow Software Synthesis: Part I
As described in Figure~\ref{fig:software_synthesis_flows}, the software synthesis process is centered around multiple abstractions.
These can be seen as formal constructs modeling the application and architectures, as well as decisions of the execution of the former on the latter, like mappings.
They are all rich in (mathematical) structure.
Architectures for example, even heterogeneous ones, exhibit a great deal of symmetry.
Similarly, the space of mappings has locality properties, where some mappings are similar whereas others are to others . Chapter~\ref{chap:structures} describes these structures.
In this thesis we aim to identify and exploit these structures in different ways.

Chapter~\ref{chap:compile-time} explores compile-time applications of the identified structures.
For example, it shows how we can use symmetries in \ac{DSE} for pruning the design space and discusses the role of locality in mapping algorithms.
Chapter~\ref{chap:mapping_other_applications}, on the other hand, explores other applications of the structures.
It shows how symmetries can also be leveraged at runtime in so-called hybrid mapping strategies.
It also discusses memory, which is traditionally neglected in mapping approaches.
\todo{The structure of the applications feels weird: can I change it?}
In Chapter~\ref{chap:mapping_conclusions} we discuss the conclusions we can make from exploring this mapping flow,
and we also discuss related work to this part in Chapter~\ref{chap:related_mappings}.

The second part of this thesis goes beyond the discussed \ac{KPN}-based flow.
Instead of the structure emerging from a concrete model, i considers the underlying models themselves.
While Software Synthesis refers to a family of methods, each concrete method has a corresponding choice of abstractions it uses.
This translates to the programming language abstractions and semantics striving for expressive idioms for programmers that permit the compiler to analyze them and execute them efficiently.
Thus, instead of exploiting the structure of the given abstractions, in the second part of this thesis we explore ways in which we can improve upon software synthesis methods by changing the structure we use: be it the semantics of the model of computation, implicit language structures or even the benchmarks we evaluate to asses our methods.

In Chapter~\ref{chap:mocs} we start with a more systematic overview of \acfp{MoC}.
We see how understanding the models and their relationships pays off by finding and exploiting a gap in the semantics between \ac{KPN} and languages that usually implement this model using blocking-reads semantics.
Expanding on the overview of \acp{MoC}, we consider the requirements of the domain of \acp{CPS}.
From these considerations we discuss a novel model, Reactors, and how it can be used in different domains like automotive and telecommunications.
In Chapter~\ref{chap:language} we go beyond the realm of \acp{CPS} and discuss how the principles of dataflow and language-based transformations can be exploited in a different domain, this time in a different domain of microservice-oriented systems. We discuss two distinct ways to exploit language-level abstractions in this domain.
Finally, in Chapter~\ref{chap:benchmarknig} we turn our attention to a seemingly orthogonal aspect: Benchmarking.
In order to asses the performance of any method or flow, we require benchmarks.
However, benchmarks are scarce and of very diverse levels of quality.
Nevertheless, we can exploit structure again to combat this problem: instead of the structure of the models and architectures, we consider the structure of the applications and their code.
We show how we can achieve this both with hand-made models, and using machine learning to learn the structure of the applications.

We discuss related work to the different aspects of this second part in Chapter~\ref{chap:related_semantics}.
We then expand our conclusions from the \ac{KPN} flow to consider these additional aspects, concluding the thesis in Chapter~\ref{chap:conlusion.}
\todo{Add a discussion of the motivation to constraint in the right way. Do I have a good example? (GOTO?), cite~\cite{tasharofi2013scala}} 

\subsection{A Note on Originality}

This thesis presents the fruits of over half a decade of research on the subjects presented.
Research, especially in an interdisciplinary approach like presented here, is much more fruitful when collaborative.
In the case of joint work, I have made an effort to focus only on my own contributions in this thesis, whenever possible.
I have also taken care to describe the work of my colleagues as theirs, when I have included it as an indispensable requirement to understand my own work.
However,  many if not most of these ideas in these thesis are the result of joint work and cannot be credited to a single person.
In those cases I have also taken care to describe the work as joint and mention other co-authors.
If in doubt, any idea or result that I have included here which has already been published elsewhere is also due to my coauthors.

%\begin{figure}[h]
%	\centering
%   \resizebox{0.55\textwidth}{!}{\input{figures/placeholder.tex}}
%	\caption{A placeholder picture.}
%	\label{fig:placeholder}
%\end{figure}
%
%\end{figure}
%\begin{figure}[h]
%	\centering
%   \resizebox{0.55\textwidth}{!}{\input{generated/placeholder_plot.tex}}
%	\caption{Placeholder plot.} %something like: https://www.karlrupp.net/wp-content/uploads/2015/06/40-years-processor-trend.png
%	\label{fig:placeholder_plot}
%\end{figure}

%A placeholder reference\cite{goens_multiprog18}.
%\begin{figure}[h]
%	\centering
%   \resizebox{0.55\textwidth}{!}{\input{figures/placeholder_flow.tex}}
%	\caption{A placeholder flow.}
%	\label{fig:placeholder_flow}
%\end{figure}

